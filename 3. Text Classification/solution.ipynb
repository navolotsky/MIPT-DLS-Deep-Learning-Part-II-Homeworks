{"cells":[{"cell_type":"markdown","metadata":{},"source":["  <img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n","  <h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"]},{"cell_type":"markdown","metadata":{},"source":["  ---"]},{"cell_type":"markdown","metadata":{},"source":["Student: Oleg Navolotsky / Наволоцкий Олег  \n","Stepik: https://stepik.org/users/2403189  \n","Telegram: [@mehwhatever0](https://t.me/mehwhatever0)  \n","\n","**Note**: reproducibility depends on [different things](https://pytorch.org/docs/stable/notes/randomness.html):\n",">Completely reproducible results are not guaranteed across PyTorch releases, individual commits, or different platforms. Furthermore, results may not be reproducible between CPU and GPU executions, even when using identical seeds.\n","\n","Some used software versions:\n","- PyTorch 1.8.0\n","- torchtext 0.9.0\n","- captum 0.3.1\n","- NumPy 1.19.2\n","- Python 3.8.8 (default, Feb 24 2021, 15:54:32) \\[MSC v.1928 64 bit (AMD64)] :: Anaconda, Inc. on win32\n","- NVIDIA Driver 461.33\n","- NVIDIA CUDA 11.2\n","- Windows 10 Pro 1909, build 18363.535\n","\n","\n","Hardware:\n","- i5 2500 8 gb\n","- GTX 1060 6 gb"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import random\n","\n","import numpy as np\n","import torch\n","\n","\n","SEED = 1234\n","\n","\n","def enable_reproducibility(\n","        seed=SEED, raise_if_no_deterministic=True,\n","        cudnn_deterministic=True, disable_cudnn_benchmarking=True):\n","    # https://pytorch.org/docs/stable/notes/randomness.html#avoiding-nondeterministic-algorithms\n","    torch.use_deterministic_algorithms(raise_if_no_deterministic)\n","\n","    # https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility\n","    os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n","    \n","    torch.backends.cudnn.benchmark = not disable_cudnn_benchmarking\n","    torch.backends.cudnn.deterministic = cudnn_deterministic\n","\n","    torch.manual_seed(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["C:\\Users\\user0\\anaconda3\\envs\\custom\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"]}],"source":["enable_reproducibility()"]},{"cell_type":"markdown","metadata":{},"source":["# Задание 3\n","\n","## Классификация текстов\n","\n","В этом задании вам предстоит попробовать несколько методов, используемых в задаче классификации, а также понять насколько хорошо модель понимает смысл слов и какие слова в примере влияют на результат.\n","\n","В этом задании мы будем использовать библиотеку torchtext. Она довольна проста в использовании и поможет нам сконцентрироваться на задаче, а не на написании Dataloader-а.\n","\n","Датасет, на котором мы будем проводить эксперименты, — это комментарии к фильмам с сайта IMDB."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset loaded from cache.\nDataset downloaded. Time spent: 0.3427903652191162\n"]}],"source":["import shelve\n","import time\n","\n","import torchtext\n","from torch.utils.data import random_split\n","\n","start = time.time()\n","with shelve.open('imdb_dataset_fast_cache') as imdb_dataset_fast_cache:\n","    if any(split not in imdb_dataset_fast_cache for split in ('train', 'valid', 'test') ):\n","        print(\"Loading dataset from slow torchtext files...\")\n","        train_valid, test = torchtext.datasets.IMDB(split=('train', 'test'))\n","        train_valid, test = list(train_valid), list(test)\n","        # default value of the argument split_ratio in torchtext.legacy.data.Data.split()\n","        split_ratio = 0.7\n","        num_train = int(len(train_valid) * split_ratio)  \n","        train, valid = random_split(train_valid, [num_train, len(train_valid) - num_train])\n","        train = list(train)\n","        valid = list(valid)\n","        imdb_dataset_fast_cache['train'] = train\n","        imdb_dataset_fast_cache['valid'] = valid\n","        imdb_dataset_fast_cache['test'] = test\n","        print(\"Dataset cached.\")\n","    else:\n","        train = imdb_dataset_fast_cache['train']\n","        valid = imdb_dataset_fast_cache['valid']\n","        test = imdb_dataset_fast_cache['test']\n","        print(\"Dataset loaded from cache.\")\n","print(f\"Dataset downloaded. Time spent: {time.time() - start}\")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["C:\\Users\\user0\\anaconda3\\envs\\custom\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"]}],"source":["from collections import Counter\n","from itertools import chain\n","\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import Vocab\n","\n","# get tokenizer as used in torchtext.legacy.data.Field by default (string.split)\n","tokenizer = get_tokenizer(None) \n","counter = Counter(chain.from_iterable(tokenizer(line) for _, line in train))\n","vocab = Vocab(counter, min_freq=1)\n","PAD_TOKEN = '<pad>'  # default special padding token in Vocab"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2, {'neg', 'pos'})"]},"metadata":{},"execution_count":5}],"source":["labels = set([label for (label, _) in chain(train, valid)])\n","num_classes = len(labels)\n","num_classes, labels"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def label_transform(label):\n","    if label == 'pos':\n","        return 1\n","    elif label == 'neg':\n","        return 0\n","    raise ValueError(f\"unknown label {label}\")\n","\n","def label_inverse_transform(idx):\n","    if idx == 1:\n","        return 'pos'\n","    elif idx == 0:\n","        return 'neg'\n","    raise ValueError(f\"unknown idx {idx}\")\n","\n","def text_transform(text, lower=True):\n","    if lower:\n","        text = text.lower()\n","    return [vocab[token] for token in tokenizer(text)]"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["from torch.nn.utils.rnn import pad_sequence\n","\n","def collate_batch(batch):\n","    label_list, text_list, texts_lengths = [], [], []\n","    for (label, text) in batch:\n","        label_list.append(label_transform(label))\n","        token_indices = text_transform(text)\n","        texts_lengths.append(len(token_indices))\n","        processed_text = torch.tensor(token_indices)\n","        text_list.append(processed_text)\n","    return torch.tensor(label_list), pad_sequence(text_list, batch_first=True, padding_value=vocab[PAD_TOKEN]), texts_lengths"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["import math\n","import random\n","\n","from torch.utils.data import DataLoader, Sampler\n","\n","\n","class BatchSamplerMimickingBucketIterator(Sampler):\n","    def __init__(self, raw_dataset_list, tokenizer, batch_size, drop_last=False, pool_size_multiplier=1, decreasing_order_within_batch=True):\n","        self._batch_size = batch_size\n","        self._drop_last = drop_last\n","        self._pool_size_multiplier = pool_size_multiplier\n","        self._indices_and_lengths = [(i, len(tokenizer(text))) for i, (_, text) in enumerate(raw_dataset_list)]\n","        self._decreasing_order_within_batch = decreasing_order_within_batch\n","    \n","    def __len__(self):\n","        round_ = math.floor if self._drop_last else math.ceil\n","        return round_(len(self._indices_and_lengths) / self._batch_size)\n","    \n","    def __iter__(self):\n","        batch_size = self._batch_size\n","        drop_last = self._drop_last\n","        pool_size = batch_size * self._pool_size_multiplier\n","        indices = self._indices_and_lengths\n","        reverse = self._decreasing_order_within_batch\n","        random.shuffle(indices)\n","        pooled_indices = []\n","        # create pool of indices with similar lengths\n","        for i in range(0, len(indices), batch_size * pool_size):\n","            pooled_indices.extend(sorted(indices[i:i + batch_size * pool_size], key=lambda x: x[1], reverse=reverse))\n","\n","        pooled_indices = [x[0] for x in pooled_indices]\n","\n","        # yield indices for current batch\n","        last_index = len(pooled_indices) - len(pooled_indices) % batch_size\n","        for i in range(0, len(pooled_indices), batch_size):\n","            if drop_last and i == last_index:\n","                break\n","            yield pooled_indices[i:i + batch_size]"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","batch_size = 64\n","# 8 * 100 is taken from here:\n","# https://github.com/pytorch/text/blob/master/examples/legacy_tutorial/migration_tutorial.ipynb\n","pool_size_multiplier = 8 * 100 // batch_size\n","\n","batch_sampler = BatchSamplerMimickingBucketIterator(train, tokenizer, batch_size, pool_size_multiplier=pool_size_multiplier, drop_last=True)\n","train_loader = DataLoader(train, batch_sampler=batch_sampler, collate_fn=collate_batch)\n","valid_loader = DataLoader(valid, batch_size=batch_size, collate_fn=collate_batch)\n","test_loader = DataLoader(test, batch_size=batch_size, collate_fn=collate_batch)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{},"source":["  ## RNN\n","\n","  Для начала попробуем использовать рекурентные нейронные сети. На семинаре вы познакомились с GRU, вы можете также попробовать LSTM. Можно использовать для классификации как hidden_state, так и output последнего токена."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["from torch import nn\n","\n","class RNNBaseline(nn.Module):\n","    def __init__(\n","            self, vocab_size, embedding_dim, hidden_dim, output_dim,\n","            n_layers, bidirectional, dropout, pad_idx):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n","        self.rnn = nn.GRU(\n","            input_size=embedding_dim,\n","            hidden_size=hidden_dim,\n","            num_layers=n_layers, dropout=dropout, bidirectional=bidirectional)\n","        self.fc = nn.Linear((bidirectional + 1) * hidden_dim, output_dim)\n","\n","    def forward(self, texts, texts_lengths):\n","        embedded = self.embedding(texts)\n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, texts_lengths, batch_first=True, enforce_sorted=False)\n","        _, hidden = self.rnn(packed_embedded)\n","        features = torch.hstack((hidden[-2], hidden[-1]))\n","        return self.fc(features)"]},{"cell_type":"markdown","metadata":{},"source":["Обучите сетку! Используйте любые вам удобные инструменты, Catalyst, PyTorch Lightning или свои велосипеды."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["from copy import deepcopy\n","\n","import numpy as np\n","from tqdm.notebook import tqdm\n","\n","def training(model, train_loader, valid_loader, patience):\n","    min_loss = np.inf\n","    cur_patience = 0\n","    for epoch in range(1, max_epochs + 1):\n","        train_loss = 0.0\n","        model.train()\n","        pbar = tqdm(enumerate(train_loader), total=len(train_loader), leave=True)\n","        pbar.set_description(f\"epoch {epoch}, training\")\n","        for it, batch in pbar: \n","            labels, texts, texts_lengths = batch\n","            labels, texts = labels.to(device), texts.to(device)\n","            if labels.ndim == 1:\n","                labels = labels.unsqueeze(1)\n","            opt.zero_grad()\n","            output = model(texts, texts_lengths)\n","            labels = labels.type_as(output)\n","            loss = loss_func(output, labels)\n","            loss.backward()\n","            opt.step()\n","            train_loss += loss.item()\n","\n","        train_loss /= len(train_loader)\n","        val_loss = 0.0\n","        model.eval()\n","        pbar = tqdm(enumerate(valid_loader), total=len(valid_loader), leave=True)\n","        pbar.set_description(f\"epoch {epoch}, validation\")\n","        with torch.no_grad():\n","            for it, batch in pbar:\n","                labels, texts, texts_lengths = batch\n","                labels, texts = labels.to(device), texts.to(device)\n","                if labels.ndim == 1:\n","                    labels = labels.unsqueeze(1)\n","                output = model(texts, texts_lengths)\n","                labels = labels.type_as(output)\n","                loss = loss_func(output, labels)\n","                val_loss += loss.item()\n","        val_loss /= len(valid_loader)\n","        spam = False\n","        if val_loss < min_loss:\n","            min_loss = val_loss\n","            best_model_state_dict = deepcopy(model.state_dict())\n","            cur_patience = 0\n","        else:\n","            cur_patience += 1\n","            if cur_patience > patience:\n","                spam = True\n","        print('Epoch: {}, Training Loss: {}, Validation Loss: {}'.format(epoch, train_loss, val_loss))\n","        if spam:\n","            print(f\"Patience is over. Training stopped after {patience + 1} epochs \"\n","                  \"without decreasing validation loss.\")\n","            break\n","    return best_model_state_dict"]},{"source":["Поиграйтесь с гиперпараметрами"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["enable_reproducibility()\n","\n","vocab_size = len(vocab)\n","pad_idx = vocab[PAD_TOKEN]\n","emb_dim = 100\n","hidden_dim = 256\n","output_dim = 1\n","n_layers = 2\n","bidirectional = True\n","dropout = 0.2\n","patience = 3\n","\n","model = RNNBaseline(\n","    vocab_size=vocab_size,\n","    embedding_dim=emb_dim,\n","    hidden_dim=hidden_dim,\n","    output_dim=output_dim,\n","    n_layers=n_layers,\n","    bidirectional=bidirectional,\n","    dropout=dropout,\n","    pad_idx=pad_idx\n",")\n","model = model.to(device)\n","\n","opt = torch.optim.Adam(model.parameters())\n","loss_func = nn.BCEWithLogitsLoss()\n","\n","max_epochs = 20"]},{"cell_type":"code","execution_count":14,"metadata":{"tags":[]},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e5571a0072c47389c684bb2f43d2a1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b46d1735db0c4fefb702dd95cd160463"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Training Loss: 0.6146579961200337, Validation Loss: 0.6222612438565593\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71ccec4774a8463ab40ef636dbbbb4f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31672d4db9bb426783a30339220583f1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Training Loss: 0.415011859529621, Validation Loss: 0.43982345686625623\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1f9b92d951f490c8f4035a9af05c372"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c872eedb6a24daca1ad45d3528c7664"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Training Loss: 0.2542561568019591, Validation Loss: 0.5177739997536449\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5afb3d17c5bf49d181a94d5b542544e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcf6c42d232249fea562741a9794b079"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Training Loss: 0.15477233025289716, Validation Loss: 0.4227705445708865\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96b436febcbf45b4834498e28937a164"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d423f182bab4797ac23579c95860ee6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Training Loss: 0.08658311832969115, Validation Loss: 0.5345852810700061\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be7a700286e64ea19d48d6f878c11c08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26d90207f4fb4a1496dfe67ea727e5d4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Training Loss: 0.038926231528584584, Validation Loss: 0.630939403832969\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff0d7ba816914893ab1f423ebe4196c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"735a37bc048545649e437871e813ed61"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Training Loss: 0.02319928084098437, Validation Loss: 0.6858035110063472\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23c65b8036de45c2b13d2e0dde9e5c11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"122d721c5b884bdcafb8da46866608be"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Training Loss: 0.01369139640509951, Validation Loss: 0.7156649151722253\nPatience is over. Training stopped after 4 epochs without decreasing validation loss.\nWall time: 6min 57s\n"]}],"source":["%%time\n","enable_reproducibility(raise_if_no_deterministic=False)\n","best_model_state_dict = training(model, train_loader, valid_loader, patience)\n","enable_reproducibility()"]},{"cell_type":"markdown","metadata":{},"source":["Посчитайте f1-score вашего классификатора на тестовом датасете."]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["from sklearn.metrics import f1_score as sk_f1_score\n","\n","@torch.no_grad()\n","def testing(model, test_loader, device):\n","    all_results = []\n","    all_labels = []\n","    model.eval()\n","    for labels, texts, texts_lengths in tqdm(test_loader, desc=\"testing\"):\n","        all_labels.append(labels)\n","        texts = texts.to(device)\n","        all_results.append(model(texts, texts_lengths))\n","    all_results = torch.cat(all_results)\n","    all_labels = torch.cat(all_labels).view(all_results.shape)\n","    return all_results, all_labels\n","\n","def binary_predict(input, output_type=torch.long):\n","    return (torch.sigmoid(input) > 0.5).type(output_type)\n","\n","def f1_score(y_pred, y_true):\n","    y_pred = y_pred.cpu().numpy()\n","    y_true = y_true.cpu().numpy()\n","    return sk_f1_score(y_true, y_pred)"]},{"source":["**Ответ**:"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["C:\\Users\\user0\\anaconda3\\envs\\custom\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"]},{"output_type":"display_data","data":{"text/plain":"testing:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b00678f43a784e148a3dcb86636c42c3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["f1-score of the RNNBaseline: 0.8428285366524009\n"]}],"source":["model.load_state_dict(best_model_state_dict)\n","outputs, labels = testing(model, test_loader, device)\n","preds = binary_predict(outputs)\n","print(f\"f1-score of the RNNBaseline: {f1_score(preds, labels)}\")"]},{"cell_type":"markdown","metadata":{},"source":["  Вы можете использовать Conv2d с `in_channels=1, kernel_size=(kernel_sizes[0], emb_dim))` или Conv1d c `in_channels=emb_dim, kernel_size=kernel_size[0]`. Но хорошенько подумайте над shape в обоих случаях."]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["C:\\Users\\user0\\anaconda3\\envs\\custom\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"]}],"source":["import torch\n","from torch import nn\n","\n","class CNN(nn.Module):\n","    def __init__(\n","        self,\n","        vocab_size, emb_dim,\n","        out_channels, kernel_sizes,\n","        dropout=0.5, classes_num=1\n","    ):\n","        super().__init__()\n","        self._init_embeddings(vocab_size, emb_dim)\n","        self._init_convs(emb_dim, out_channels, kernel_sizes)\n","        self._init_fc(len(kernel_sizes) * out_channels, classes_num)\n","\n","    def _init_embeddings(self, vocab_size, emb_dim):\n","        self.embedding = nn.Embedding(vocab_size, emb_dim)\n","\n","    def _init_convs(self, in_channels, out_channels, kernel_sizes):\n","        convs = []\n","        for i, kernel_size in enumerate(kernel_sizes):\n","            convs.append(\n","                nn.Sequential(\n","                    nn.Conv1d(\n","                        in_channels=in_channels,\n","                        out_channels=out_channels,\n","                        kernel_size=kernel_size),\n","                    nn.ReLU(inplace=True),\n","                    nn.AdaptiveMaxPool1d(1),\n","                    nn.Dropout(dropout)\n","                )\n","            )\n","        self.convs = nn.ModuleList(convs)\n","\n","    def _init_fc(self, features_num, classes_num):\n","        self.fc = nn.Linear(features_num, classes_num)\n","        \n","    def forward(self, texts, *_): \n","        embedded = self.embedding(texts)\n","        embedded = embedded.permute(0, 2, 1)\n","        conved = [conv(embedded) for conv in self.convs]\n","        features = torch.cat(conved, dim=1).squeeze(-1)\n","        return self.fc(features)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["kernel_sizes = [3, 4, 5]\n","vocab_size = len(vocab)\n","out_channels = 64\n","dropout = 0.5\n","dim = 300\n","patience = 3\n","\n","model = CNN(vocab_size=vocab_size, emb_dim=dim, out_channels=out_channels,\n","            kernel_sizes=kernel_sizes, dropout=dropout)\n","model.to(device)\n","opt = torch.optim.Adam(model.parameters())\n","loss_func = nn.BCEWithLogitsLoss()\n","max_epochs = 30"]},{"cell_type":"markdown","metadata":{},"source":["  Обучите!"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad11e23bb30949bfb28ad80e188678d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d75a264b3f84624b4878d063b3523b1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Training Loss: 0.6446519849937914, Validation Loss: 0.48709957705715956\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33f67d4108ae44af8648d085d2f9a85a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3d4dc1a37b14610b808d55f65c367d5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Training Loss: 0.4992998676858979, Validation Loss: 0.4255752631668317\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80163f5928084991bcff1e1afc5341ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f128c90a3fb4ca99fec22c8d5a58059"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Training Loss: 0.4284234596041096, Validation Loss: 0.3751080806477595\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b913c717bf0c4b3abad1ea1a18217265"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03634e9d3c384a5da9c0d758668c710d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Training Loss: 0.35162894094819985, Validation Loss: 0.36326472372826885\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fce89101a661471991c6d91d5cdd87bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94cc36802de04dbd88bc0c1fbe599894"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Training Loss: 0.2756578110895314, Validation Loss: 0.3750240553991269\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"428151bf9aca4a61a938ed5804f6b17d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62e587715d42424b9f81df8d2b07192f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Training Loss: 0.2077772510357392, Validation Loss: 0.4353838670304266\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8b7f60ec9e34588af44138f83c993fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f554dde5b2e4a18b6b3eabb98ecd0a2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Training Loss: 0.1490694847940416, Validation Loss: 0.458261256121983\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b2bdba2f7ce46a4b1bdd0f9c1a0a0ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f151a6d08814dc0b7ce5626fb788e6b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Training Loss: 0.09036829796766405, Validation Loss: 0.528672018041045\nPatience is over. Training stopped after 4 epochs without decreasing validation loss.\nWall time: 3min 38s\n"]}],"source":["%%time\n","enable_reproducibility(raise_if_no_deterministic=False)\n","best_model_state_dict = training(model, train_loader, valid_loader, patience)\n","enable_reproducibility()"]},{"cell_type":"markdown","metadata":{},"source":["  Посчитайте f1-score вашего классификатора.\n","\n","  **Ответ**:"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"output_type":"display_data","data":{"text/plain":"testing:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c43c9dea84d94725a0a23cc9ba7d5074"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["f1-score of the CNN: 0.8434916282354897\n"]}],"source":["model.load_state_dict(best_model_state_dict)\n","outputs, labels = testing(model, test_loader, device)\n","preds = binary_predict(outputs)\n","print(f\"f1-score of the CNN: {f1_score(preds, labels)}\")"]},{"cell_type":"markdown","metadata":{},"source":["  ## Интерпретируемость\n","\n","  Посмотрим, куда смотрит наша модель. Достаточно запустить код ниже."]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["C:\\Users\\user0\\anaconda3\\envs\\custom\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"]}],"source":["# !conda install captum -c pytorch"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["C:\\Users\\user0\\anaconda3\\envs\\custom\\lib\\site-packages\\ipykernel\\pylab\\config.py:70: DeprecationWarning: InlineBackend._figure_formats_changed is deprecated in traitlets 4.1: use @observe and @unobserve instead.\n  def _figure_formats_changed(self, name, old, new):\n"]}],"source":["from captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization\n","\n","\n","def get_sentence_min_len():\n","    kernel_sizes = globals().get('kernel_sizes')\n","    return max(kernel_sizes) if kernel_sizes is not None else 7\n","\n","def forward_with_softmax(model, input):\n","    logits = model(input)\n","    return torch.softmax(logits, 0)[0][1]\n","\n","def forward_with_sigmoid(model, input):\n","    return torch.sigmoid(model(input))\n","\n","# accumalate couple samples in this array for visualization purposes\n","vis_data_records_ig = []\n","\n","def interpret_sentence(model, sentence, label=0, min_len=None, print_result=False):\n","    model.eval()\n","    text = [tok for tok in tokenizer(sentence)]\n","    if min_len is None:\n","        min_len = get_sentence_min_len()\n","    if len(text) < min_len:\n","        text += [PAD_TOKEN] * (min_len - len(text))\n","    indexed = [vocab[t] for t in text]\n","\n","    model.zero_grad()\n","\n","    input_indices = torch.tensor(indexed, device=device)\n","    input_indices = input_indices.unsqueeze(0)\n","    \n","    # input_indices dim: [sequence_length]\n","    seq_length = len(text)\n","\n","    # predict\n","    pred = forward_with_sigmoid(model, input_indices).item()\n","    pred_ind = round(pred)\n","\n","    # generate reference indices for each sample\n","    reference_indices = token_reference.generate_reference(seq_length, device=device).unsqueeze(0)\n","\n","    # compute attributions and approximation delta using layer integrated gradients\n","    attributions_ig, delta = lig.attribute(input_indices, reference_indices, n_steps=5000, return_convergence_delta=True)\n","    if print_result:\n","        print(\"text: \", sentence)\n","        print(f\"true: {label_inverse_transform(label)}, pred: {label_inverse_transform(pred_ind)} ({pred:.2f}), delta: {abs(delta.item())}\")\n","\n","    add_attributions_to_visualizer(attributions_ig, text, pred, pred_ind, label, delta, vis_data_records_ig)\n","    \n","def add_attributions_to_visualizer(attributions, text, pred, pred_ind, label, delta, vis_data_records):\n","    attributions = attributions.sum(dim=2).squeeze(0)\n","    attributions = attributions / torch.norm(attributions)\n","    attributions = attributions.cpu().detach().numpy()\n","\n","    # storing couple samples in an array for visualization purposes\n","    vis_data_records.append(\n","        visualization.VisualizationDataRecord(\n","            attributions,\n","            pred,\n","            label_inverse_transform(pred_ind),\n","            label_inverse_transform(label),\n","            label_inverse_transform(1),\n","            attributions.sum(),       \n","            text,\n","            delta\n","        )\n","    )"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["C:\\Users\\user0\\anaconda3\\envs\\custom\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"]}],"source":["predefined_sentences = [\n","    ('It was a fantastic performance !', 1),\n","    ('Best film ever', 1),\n","    ('Such a great show!', 1),\n","    ('It was a horrible movie', 0),\n","    ('I\\'ve never watched something as bad', 0),\n","    ('It is a disgusting movie!', 0),\n","]"]},{"cell_type":"markdown","metadata":{},"source":["Попробуйте добавить свои примеры!"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["my_sentences = [\n","    (\"It is definitely worth watching\", 1),\n","    (\"This movie made my evening\", 1),\n","    (\"You'll want to advice your enemies to watch it\", 0),\n","    (\"No way you find more useless thing to spend your time\", 0)\n","]\n","\n","def show_visualization(model, sentences):\n","    global token_reference, lig, vis_data_records_ig\n","    token_reference = TokenReferenceBase(reference_token_idx=vocab[PAD_TOKEN])\n","    lig = LayerIntegratedGradients(model, model.embedding)\n","    vis_data_records_ig = []\n","    enable_reproducibility(raise_if_no_deterministic=False)\n","    for sentence, label in sentences:\n","        interpret_sentence(model, sentence, label)\n","    enable_reproducibility()\n","    print('Visualize attributions based on Integrated Gradients')\n","    visualization.visualize_text(vis_data_records_ig)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Visualize attributions based on Integrated Gradients\n"]},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.97)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>1.30</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 53%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fantastic                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> performance                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.65)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>1.19</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 78%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Best                    </font></mark><mark style=\"background-color: hsl(120, 75%, 56%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> film                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ever                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.87)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>1.07</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Such                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 51%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> great                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> show!                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.18)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-0.56</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 65%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> horrible                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.39)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-0.23</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> I've                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> never                    </font></mark><mark style=\"background-color: hsl(0, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> watched                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> something                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 70%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.69)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>1.62</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(120, 75%, 74%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 60%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> disgusting                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie!                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.89)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>1.00</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 64%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> definitely                    </font></mark><mark style=\"background-color: hsl(120, 75%, 71%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> worth                    </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> watching                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.57)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>0.56</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 76%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> This                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> made                    </font></mark><mark style=\"background-color: hsl(120, 75%, 68%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> my                    </font></mark><mark style=\"background-color: hsl(0, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> evening                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.44)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-0.43</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> You'll                    </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> want                    </font></mark><mark style=\"background-color: hsl(120, 75%, 74%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> advice                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> your                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> enemies                    </font></mark><mark style=\"background-color: hsl(0, 75%, 71%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> watch                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.50)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>0.02</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> No                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> way                    </font></mark><mark style=\"background-color: hsl(120, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> you                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> find                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> more                    </font></mark><mark style=\"background-color: hsl(0, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> useless                    </font></mark><mark style=\"background-color: hsl(0, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> thing                    </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> spend                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> your                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> time                    </font></mark></td><tr></table>"},"metadata":{}}],"source":["show_visualization(model, predefined_sentences + my_sentences)"]},{"cell_type":"markdown","metadata":{},"source":["  ## Эмбэдинги слов\n","\n","  Вы ведь не забыли, как мы можем применить знания о word2vec и GloVe. Давайте попробуем!"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["import numpy as np\n","import torch\n","from torch import nn\n","\n","class CNNUsingPretrainedEmbeddings(CNN):\n","    def __init__(\n","        self,\n","        embeddings,\n","        out_channels, kernel_sizes,\n","        dropout=0.5, classes_num=1\n","    ):\n","        nn.Module.__init__(self)\n","        self._init_embeddings(embeddings)\n","        self._init_convs(self.embedding.embedding_dim, out_channels, kernel_sizes)\n","        self._init_fc(len(kernel_sizes) * out_channels, classes_num)\n","\n","    def _init_embeddings(self, embeddings):\n","        if isinstance(embeddings, np.ndarray):\n","            embeddings = torch.from_numpy(embeddings)\n","        self.embedding = nn.Embedding.from_pretrained(embeddings)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["from torchtext.vocab import GloVe\n","\n","vocab = Vocab(counter, vectors=GloVe(name='6B', dim=300), min_freq=1)  # text_transform() will find it in the global scope"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["kernel_sizes = [3, 4, 5]\n","vocab_size = len(vocab)\n","out_channels = 64\n","dropout = 0.5\n","dim = 300\n","patience = 3\n","\n","model = CNNUsingPretrainedEmbeddings(embeddings=vocab.vectors, out_channels=out_channels,\n","            kernel_sizes=kernel_sizes, dropout=dropout)\n","model.to(device)\n","opt = torch.optim.Adam(model.parameters())\n","loss_func = nn.BCEWithLogitsLoss()\n","max_epochs = 30"]},{"cell_type":"markdown","metadata":{},"source":["Вы знаете, что делать."]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"912992841af0476f9c29df757e0b1319"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9103c02c20348aeb40dffbd057525b0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Training Loss: 0.496580944393144, Validation Loss: 0.3799072001445091\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a31cdef9b93489e93e2a59bde4d8292"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67b3a9a6bcca4eff9d52055fe6c926a0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Training Loss: 0.3741347910392852, Validation Loss: 0.35343898188764766\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3ad59490fb44cf6a30528c5b55c2a92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eed68181178c41d99fbab6fe2bdfe7a7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Training Loss: 0.32974767553937306, Validation Loss: 0.34037109464406967\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f1edc6d9fc44084b8c2d68df577da2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9f2fbf0e3d74fac9e7e77f6042bf35d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Training Loss: 0.2910369736698521, Validation Loss: 0.33756355777130287\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e6db8715e074ffa86d7e61ec66aa3bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f645f674eb844d94aef36f669b31ed42"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Training Loss: 0.26507175285300927, Validation Loss: 0.3368449385388423\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fbc58f6c0d4407790f88cac16b1a8ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c42cee924d7c44e59aa58d7cb14b9162"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Training Loss: 0.23151345802095782, Validation Loss: 0.34697062054933125\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef08910373b74d62a624a08908ef93f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c00dc62b8d44b0f939ac221847a37c9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Training Loss: 0.21334638419277938, Validation Loss: 0.35341593118037207\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f393dfe0eb0048979a71a61116680588"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bba189b21f374d0daf477077eef04a95"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Training Loss: 0.19667354294341124, Validation Loss: 0.37053701660390626\n"]},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67488f42b5864bfa9f84a420f04f9d80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/118 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f42a3942949c43b3b0bc402159c52fcc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Training Loss: 0.17398141480081683, Validation Loss: 0.4084903116701013\nPatience is over. Training stopped after 4 epochs without decreasing validation loss.\nWall time: 1min 52s\n"]}],"source":["%%time\n","enable_reproducibility(raise_if_no_deterministic=False)\n","best_model_state_dict = training(model, train_loader, valid_loader, patience)\n","enable_reproducibility()"]},{"cell_type":"markdown","metadata":{},"source":["Посчитайте f1-score вашего классификатора.\n","\n","**Ответ**:"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"output_type":"display_data","data":{"text/plain":"testing:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e541224a45da4dab89b50c2e6db710d1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["f1-score of the CNNUsingPretrainedEmbeddings: 0.8589970016839857\n"]}],"source":["model.load_state_dict(best_model_state_dict)\n","outputs, labels = testing(model, test_loader, device)\n","preds = binary_predict(outputs)\n","print(f\"f1-score of the CNNUsingPretrainedEmbeddings: {f1_score(preds, labels)}\")"]},{"cell_type":"markdown","metadata":{},"source":["Проверим насколько все хорошо!"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["C:\\Users\\user0\\anaconda3\\envs\\custom\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n","Visualize attributions based on Integrated Gradients\n"]},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.95)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>1.00</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 53%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> fantastic                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> performance                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> !                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.54)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>0.27</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Best                    </font></mark><mark style=\"background-color: hsl(0, 75%, 78%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> film                    </font></mark><mark style=\"background-color: hsl(120, 75%, 59%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ever                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #pad                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.87)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>1.06</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Such                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(120, 75%, 51%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> great                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> show!                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> #pad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.17)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-0.80</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> was                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 62%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> horrible                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.49)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-0.18</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> I've                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> never                    </font></mark><mark style=\"background-color: hsl(120, 75%, 75%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> watched                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> something                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> as                    </font></mark><mark style=\"background-color: hsl(0, 75%, 68%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bad                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.24)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-0.65</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 63%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> disgusting                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie!                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.77)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>1.06</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> definitely                    </font></mark><mark style=\"background-color: hsl(120, 75%, 52%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> worth                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> watching                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.55)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>0.58</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> This                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> made                    </font></mark><mark style=\"background-color: hsl(120, 75%, 59%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> my                    </font></mark><mark style=\"background-color: hsl(120, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> evening                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>pos (0.56)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>0.49</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> You'll                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> want                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> advice                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> your                    </font></mark><mark style=\"background-color: hsl(120, 75%, 59%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> enemies                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> watch                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> it                    </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>neg</b></text></td><td><text style=\"padding-right:2em\"><b>neg (0.31)</b></text></td><td><text style=\"padding-right:2em\"><b>pos</b></text></td><td><text style=\"padding-right:2em\"><b>-0.54</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> No                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> way                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> you                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> find                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> more                    </font></mark><mark style=\"background-color: hsl(0, 75%, 62%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> useless                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> thing                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> to                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> spend                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> your                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> time                    </font></mark></td><tr></table>"},"metadata":{}}],"source":["show_visualization(model, predefined_sentences + my_sentences)"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8-final"},"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}}}