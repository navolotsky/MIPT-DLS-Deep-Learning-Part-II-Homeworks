{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":" [homework]classification.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Ot3c4fjZwC4T"},"source":["<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n","<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"]},{"cell_type":"markdown","metadata":{"id":"P2JdzEXmwRU5"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"TItJgQMp5p4E"},"source":["# Задание 3\n","\n","## Классификация текстов\n","\n","В этом задании вам предстоит попробовать несколько методов, используемых в задаче классификации, а также понять насколько хорошо модель понимает смысл слов и какие слова в примере влияют на результат."]},{"cell_type":"code","metadata":{"id":"1emhHMhniZMu"},"source":["import pandas as pd\n","import numpy as np\n","import torch\n","\n","from torchtext import datasets\n","\n","from torchtext.data import Field, LabelField\n","from torchtext.data import BucketIterator\n","\n","from torchtext.vocab import Vectors, GloVe\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import random\n","from tqdm.autonotebook import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XyOlPZA26Ppy"},"source":["В этом задании мы будем использовать библиотеку torchtext. Она довольна проста в использовании и поможет нам сконцентрироваться на задаче, а не на написании Dataloader-а."]},{"cell_type":"code","metadata":{"id":"-VuQ1E10_tX_"},"source":["TEXT = Field(sequential=True, lower=True, include_lengths=True)  # Поле текста\n","LABEL = LabelField(dtype=torch.float)  # Поле метки"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SBK4ipzS122j"},"source":["SEED = 1234\n","\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nNWLG7mG6n2d"},"source":["Датасет на котором мы будем проводить эксперементы это комментарии к фильмам из сайта IMDB."]},{"cell_type":"code","metadata":{"id":"mRzUSWeAi6Xq"},"source":["train, test = datasets.IMDB.splits(TEXT, LABEL)  # загрузим датасет\n","train, valid = train.split(random_state=random.seed(SEED))  # разобьем на части"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uQfIRhWPjURL"},"source":["TEXT.build_vocab(train)\n","LABEL.build_vocab(train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bSoBkdcj4roR"},"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","train_iter, valid_iter, test_iter = BucketIterator.splits(\n","    (train, valid, test), \n","    batch_size = 64,\n","    sort_within_batch = True,\n","    device = device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3_CRDES360wG"},"source":["## RNN\n","\n","Для начала попробуем использовать рекурентные нейронные сети. На семинаре вы познакомились с GRU, вы можете также попробовать LSTM. Можно использовать для классификации как hidden_state, так и output последнего токена."]},{"cell_type":"code","metadata":{"id":"J1yE1KPQqDat"},"source":["class RNNBaseline(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n","                 bidirectional, dropout, pad_idx):\n","        \n","        super().__init__()\n","        \n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n","        \n","        self.rnn = None  # YOUR CODE GOES HERE\n","        \n","        self.fc = None  # YOUR CODE GOES HERE\n","        \n","        \n","    def forward(self, text, text_lengths):\n","        \n","        #text = [sent len, batch size]\n","        \n","        embedded = self.embedding(text)\n","        \n","        #embedded = [sent len, batch size, emb dim]\n","        \n","        #pack sequence\n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n","        \n","        # cell arg for LSTM, remove for GRU\n","        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n","        #unpack sequence\n","        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)  \n","\n","        #output = [sent len, batch size, hid dim * num directions]\n","        #output over padding tokens are zero tensors\n","        \n","        #hidden = [num layers * num directions, batch size, hid dim]\n","        #cell = [num layers * num directions, batch size, hid dim]\n","        \n","        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n","        #and apply dropout\n","        \n","        hidden = None  # YOUR CODE GOES HERE\n","                \n","        #hidden = [batch size, hid dim * num directions] or [batch_size, hid dim * num directions]\n","            \n","        return self.fc(hidden)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U7dLGFg4M7Te"},"source":["Поиграйтесь с гиперпараметрами"]},{"cell_type":"code","metadata":{"id":"ggTiORJ-8t0J"},"source":["vocab_size = len(TEXT.vocab)\n","emb_dim = 100\n","hidden_dim = 256\n","output_dim = 1\n","n_layers = 2\n","bidirectional = True\n","dropout = 0.2\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","patience=3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mIiM_ZBt9_91"},"source":["model = RNNBaseline(\n","    vocab_size=vocab_size,\n","    embedding_dim=emb_dim,\n","    hidden_dim=hidden_dim,\n","    output_dim=output_dim,\n","    n_layers=n_layers,\n","    bidirectional=bidirectional,\n","    dropout=dropout,\n","    pad_idx=PAD_IDX\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mFeG88M--NbD"},"source":["model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"olAS-mVI-VfT"},"source":["opt = torch.optim.Adam(model.parameters())\n","loss_func = nn.BCEWithLogitsLoss()\n","\n","max_epochs = 20"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5jlfEAJu9akO"},"source":["Обучите сетку! Используйте любые вам удобные инструменты, Catalyst, PyTorch Lightning или свои велосипеды."]},{"cell_type":"code","metadata":{"id":"87dgw6ok9hR0"},"source":["import numpy as np\n","\n","min_loss = np.inf\n","\n","cur_patience = 0\n","\n","for epoch in range(1, max_epochs + 1):\n","    train_loss = 0.0\n","    model.train()\n","    pbar = tqdm(enumerate(train_iter), total=len(train_iter), leave=False)\n","    pbar.set_description(f\"Epoch {epoch}\")\n","    for it, batch in pbar: \n","        #YOUR CODE GOES HERE\n","\n","    train_loss /= len(train_iter)\n","    val_loss = 0.0\n","    model.eval()\n","    pbar = tqdm(enumerate(valid_iter), total=len(valid_iter), leave=False)\n","    pbar.set_description(f\"Epoch {epoch}\")\n","    for it, batch in pbar:\n","        # YOUR CODE GOES HERE\n","    val_loss /= len(valid_iter)\n","    if val_loss < min_loss:\n","        min_loss = val_loss\n","        best_model = model.state_dict()\n","    else:\n","        cur_patience += 1\n","        if cur_patience == patience:\n","            cur_patience = 0\n","            break\n","    \n","    print('Epoch: {}, Training Loss: {}, Validation Loss: {}'.format(epoch, train_loss, val_loss))\n","model.load_state_dict(best_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y4i-Go_ICT_U"},"source":["Посчитайте f1-score вашего классификатора на тестовом датасете.\n","\n","**Ответ**:"]},{"cell_type":"code","metadata":{"id":"gWkbCpNECflR"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kzDqc3__JIMe"},"source":["## CNN\n","\n","![](https://www.researchgate.net/publication/333752473/figure/fig1/AS:769346934673412@1560438011375/Standard-CNN-on-text-classification.png)\n","\n","Для классификации текстов также часто используют сверточные нейронные сети. Идея в том, что как правило сентимент содержат словосочетания из двух-трех слов, например \"очень хороший фильм\" или \"невероятная скука\". Проходясь сверткой по этим словам мы получим какой-то большой скор и выхватим его с помощью MaxPool. Далее идет обычная полносвязная сетка. Важный момент: свертки применяются не последовательно, а параллельно. Давайте попробуем!"]},{"cell_type":"code","metadata":{"id":"rU-76tNI-STt"},"source":["TEXT = Field(sequential=True, lower=True, batch_first=True)  # batch_first тк мы используем conv  \n","LABEL = LabelField(batch_first=True, dtype=torch.float)\n","\n","train, tst = datasets.IMDB.splits(TEXT, LABEL)\n","trn, vld = train.split(random_state=random.seed(SEED))\n","\n","TEXT.build_vocab(trn)\n","LABEL.build_vocab(trn)\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RQpS9KKUJQVH"},"source":["train_iter, val_iter, test_iter = BucketIterator.splits(\n","        (trn, vld, tst),\n","        batch_sizes=(128, 256, 256),\n","        sort=False,\n","        sort_key= lambda x: len(x.src),\n","        sort_within_batch=False,\n","        device=device,\n","        repeat=False,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"asgbwMePPNNl"},"source":["Вы можете использовать Conv2d с `in_channels=1, kernel_size=(kernel_sizes[0], emb_dim))` или Conv1d c `in_channels=emb_dim, kernel_size=kernel_size[0]`. Но хорошенько подумайте над shape в обоих случаях."]},{"cell_type":"code","metadata":{"id":"qPP_-0E-JYTQ"},"source":["class CNN(nn.Module):\n","    def __init__(\n","        self,\n","        vocab_size,\n","        emb_dim,\n","        out_channels,\n","        kernel_sizes,\n","        dropout=0.5,\n","    ):\n","        super().__init__()\n","        \n","        self.embedding = nn.Embedding(vocab_size, emb_dim)\n","        self.conv_0 = None  # YOUR CODE GOES HERE\n","        \n","        self.conv_1 = None  # YOUR CODE GOES HERE\n","        \n","        self.conv_2 = None  # YOUR CODE GOES HERE\n","        \n","        self.fc = nn.Linear(len(kernel_sizes) * out_channels, 1)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","        \n","    def forward(self, text):\n","        \n","        embedded = self.embedding(text)\n","        \n","        embedded = embedded  # may be reshape here\n","        \n","        conved_0 = F.relu(self.conv_0(embedded))  # may be reshape here\n","        conved_1 = F.relu(self.conv_1(embedded))  # may be reshape here\n","        conved_2 = F.relu(self.conv_2(embedded))  # may be reshape here\n","        \n","        pooled_0 = F.max_pool1d(conved_0, conved_0.shape[2]).squeeze(2)\n","        pooled_1 = F.max_pool1d(conved_1, conved_1.shape[2]).squeeze(2)\n","        pooled_2 = F.max_pool1d(conved_2, conved_2.shape[2]).squeeze(2)\n","        \n","        cat = self.dropout(torch.cat((pooled_0, pooled_1, pooled_2), dim=1))\n","            \n","        return self.fc(cat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y-U_2T5oKNed"},"source":["kernel_sizes = [3, 4, 5]\n","vocab_size = len(TEXT.vocab)\n","out_channels=64\n","dropout = 0.5\n","dim = 300\n","\n","model = CNN(vocab_size=vocab_size, emb_dim=dim, out_channels=out_channels,\n","            kernel_sizes=kernel_sizes, dropout=dropout)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vC2ThnfNKPIR"},"source":["model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mExblVtPKRw4"},"source":["opt = torch.optim.Adam(model.parameters())\n","loss_func = nn.BCEWithLogitsLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QVwSgwkEKTw5"},"source":["max_epochs = 30"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VIQgLCELDoOA"},"source":["Обучите!"]},{"cell_type":"code","metadata":{"id":"zQZbJ791KXHb"},"source":["import numpy as np\n","\n","min_loss = np.inf\n","\n","cur_patience = 0\n","\n","for epoch in range(1, max_epochs + 1):\n","    train_loss = 0.0\n","    model.train()\n","    pbar = tqdm(enumerate(train_iter), total=len(train_iter), leave=False)\n","    pbar.set_description(f\"Epoch {epoch}\")\n","    for it, batch in pbar: \n","        #YOUR CODE GOES HERE\n","\n","    train_loss /= len(train_iter)\n","    val_loss = 0.0\n","    model.eval()\n","    pbar = tqdm(enumerate(valid_iter), total=len(valid_iter), leave=False)\n","    pbar.set_description(f\"Epoch {epoch}\")\n","    for it, batch in pbar:\n","        # YOUR CODE GOES HERE\n","    val_loss /= len(valid_iter)\n","    if val_loss < min_loss:\n","        min_loss = val_loss\n","        best_model = model.state_dict()\n","    else:\n","        cur_patience += 1\n","        if cur_patience == patience:\n","            cur_patience = 0\n","            break\n","    \n","    print('Epoch: {}, Training Loss: {}, Validation Loss: {}'.format(epoch, train_loss, val_loss))\n","model.load_state_dict(best_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1UVCacK0EhPR"},"source":["Посчитайте f1-score вашего классификатора.\n","\n","**Ответ**:"]},{"cell_type":"markdown","metadata":{"id":"7VspGMN0ESiS"},"source":["## Интерпретируемость\n","\n","Посмотрим, куда смотрит наша модель. Достаточно запустить код ниже."]},{"cell_type":"code","metadata":{"id":"ye2SvjXrPgJh"},"source":["!pip install -q captum"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6e5XPKSZO6DY"},"source":["from captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization\n","\n","PAD_IND = TEXT.vocab.stoi['pad']\n","\n","token_reference = TokenReferenceBase(reference_token_idx=PAD_IND)\n","lig = LayerIntegratedGradients(model, model.embedding)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DvqWhd-fPe9e"},"source":["def forward_with_softmax(inp):\n","    logits = model(inp)\n","    return torch.softmax(logits, 0)[0][1]\n","\n","def forward_with_sigmoid(input):\n","    return torch.sigmoid(model(input))\n","\n","\n","# accumalate couple samples in this array for visualization purposes\n","vis_data_records_ig = []\n","\n","def interpret_sentence(model, sentence, min_len = 7, label = 0):\n","    model.eval()\n","    text = [tok for tok in TEXT.tokenize(sentence)]\n","    if len(text) < min_len:\n","        text += ['pad'] * (min_len - len(text))\n","    indexed = [TEXT.vocab.stoi[t] for t in text]\n","\n","    model.zero_grad()\n","\n","    input_indices = torch.tensor(indexed, device=device)\n","    input_indices = input_indices.unsqueeze(0)\n","    \n","    # input_indices dim: [sequence_length]\n","    seq_length = min_len\n","\n","    # predict\n","    pred = forward_with_sigmoid(input_indices).item()\n","    pred_ind = round(pred)\n","\n","    # generate reference indices for each sample\n","    reference_indices = token_reference.generate_reference(seq_length, device=device).unsqueeze(0)\n","\n","    # compute attributions and approximation delta using layer integrated gradients\n","    attributions_ig, delta = lig.attribute(input_indices, reference_indices, \\\n","                                           n_steps=5000, return_convergence_delta=True)\n","\n","    print('pred: ', LABEL.vocab.itos[pred_ind], '(', '%.2f'%pred, ')', ', delta: ', abs(delta))\n","\n","    add_attributions_to_visualizer(attributions_ig, text, pred, pred_ind, label, delta, vis_data_records_ig)\n","    \n","def add_attributions_to_visualizer(attributions, text, pred, pred_ind, label, delta, vis_data_records):\n","    attributions = attributions.sum(dim=2).squeeze(0)\n","    attributions = attributions / torch.norm(attributions)\n","    attributions = attributions.cpu().detach().numpy()\n","\n","    # storing couple samples in an array for visualization purposes\n","    vis_data_records.append(visualization.VisualizationDataRecord(\n","                            attributions,\n","                            pred,\n","                            LABEL.vocab.itos[pred_ind],\n","                            LABEL.vocab.itos[label],\n","                            LABEL.vocab.itos[1],\n","                            attributions.sum(),       \n","                            text,\n","                            delta))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VtYy633vS8Me"},"source":["interpret_sentence(model, 'It was a fantastic performance !', label=1)\n","interpret_sentence(model, 'Best film ever', label=1)\n","interpret_sentence(model, 'Such a great show!', label=1)\n","interpret_sentence(model, 'It was a horrible movie', label=0)\n","interpret_sentence(model, 'I\\'ve never watched something as bad', label=0)\n","interpret_sentence(model, 'It is a disgusting movie!', label=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aqIRSCWlRTOe"},"source":["Попробуйте добавить свои примеры!"]},{"cell_type":"code","metadata":{"id":"4URAkcWXTGBi"},"source":["print('Visualize attributions based on Integrated Gradients')\n","visualization.visualize_text(vis_data_records_ig)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SvEHEaurElu8"},"source":["## Эмбэдинги слов\n","\n","Вы ведь не забыли, как мы можем применить знания о word2vec и GloVe. Давайте попробуем!"]},{"cell_type":"code","metadata":{"id":"iW46gGLNuo0q"},"source":["TEXT.build_vocab(trn, vectors=)# YOUR CODE GOES HERE\n","# подсказка: один из импортов пока не использовался, быть может он нужен в строке выше :)\n","LABEL.build_vocab(trn)\n","\n","word_embeddings = TEXT.vocab.vectors\n","\n","kernel_sizes = [3, 4, 5]\n","vocab_size = len(TEXT.vocab)\n","dropout = 0.5\n","dim = 300"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MZ4YwLlcltm3"},"source":["train, tst = datasets.IMDB.splits(TEXT, LABEL)\n","trn, vld = train.split(random_state=random.seed(SEED))\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","train_iter, val_iter, test_iter = BucketIterator.splits(\n","        (trn, vld, tst),\n","        batch_sizes=(128, 256, 256),\n","        sort=False,\n","        sort_key= lambda x: len(x.src),\n","        sort_within_batch=False,\n","        device=device,\n","        repeat=False,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2l5pDvZgl7Fp"},"source":["model = CNN(vocab_size=vocab_size, emb_dim=dim, out_channels=64,\n","            kernel_sizes=kernel_sizes, dropout=dropout)\n","\n","word_embeddings = TEXT.vocab.vectors\n","\n","prev_shape = model.embedding.weight.shape\n","\n","model.embedding.weight = # инициализируйте эмбэдинги\n","\n","assert prev_shape == model.embedding.weight.shape\n","model.to(device)\n","\n","opt = torch.optim.Adam(model.parameters())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IwiQjcuiFGTC"},"source":["Вы знаете, что делать."]},{"cell_type":"code","metadata":{"id":"fNqcFHT8cT0b"},"source":["import numpy as np\n","\n","min_loss = np.inf\n","\n","cur_patience = 0\n","\n","for epoch in range(1, max_epochs + 1):\n","    train_loss = 0.0\n","    model.train()\n","    pbar = tqdm(enumerate(train_iter), total=len(train_iter), leave=False)\n","    pbar.set_description(f\"Epoch {epoch}\")\n","    for it, batch in pbar: \n","        #YOUR CODE GOES HERE\n","\n","    train_loss /= len(train_iter)\n","    val_loss = 0.0\n","    model.eval()\n","    pbar = tqdm(enumerate(valid_iter), total=len(valid_iter), leave=False)\n","    pbar.set_description(f\"Epoch {epoch}\")\n","    for it, batch in pbar:\n","        # YOUR CODE GOES HERE\n","    val_loss /= len(valid_iter)\n","    if val_loss < min_loss:\n","        min_loss = val_loss\n","        best_model = model.state_dict()\n","    else:\n","        cur_patience += 1\n","        if cur_patience == patience:\n","            cur_patience = 0\n","            break\n","    \n","    print('Epoch: {}, Training Loss: {}, Validation Loss: {}'.format(epoch, train_loss, val_loss))\n","model.load_state_dict(best_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R2IdEWJQKESg"},"source":["Посчитайте f1-score вашего классификатора.\n","\n","**Ответ**:"]},{"cell_type":"code","metadata":{"id":"kizk028eRF0R"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4sl7h_wIRGPD"},"source":["Проверим насколько все хорошо!"]},{"cell_type":"code","metadata":{"id":"iPCm55FLir3e"},"source":["PAD_IND = TEXT.vocab.stoi['pad']\n","\n","token_reference = TokenReferenceBase(reference_token_idx=PAD_IND)\n","lig = LayerIntegratedGradients(model, model.embedding)\n","vis_data_records_ig = []\n","\n","interpret_sentence(model, 'It was a fantastic performance !', label=1)\n","interpret_sentence(model, 'Best film ever', label=1)\n","interpret_sentence(model, 'Such a great show!', label=1)\n","interpret_sentence(model, 'It was a horrible movie', label=0)\n","interpret_sentence(model, 'I\\'ve never watched something as bad', label=0)\n","interpret_sentence(model, 'It is a disgusting movie!', label=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NMDazB3AlFWA"},"source":["print('Visualize attributions based on Integrated Gradients')\n","visualization.visualize_text(vis_data_records_ig)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"flCZHdAVlL7W"},"source":[],"execution_count":null,"outputs":[]}]}